# Basic
gpu_id: 0

# dataset
data_path: "./Dataset/"
filename: 'ETTh1.csv'   # train_double_1h_2023_0217-0331.csv  train_double_1h_drift_2023_0217-0331.csv
test_path: './Dataset/ETTh1.csv'
# Graph
graph_path : "./Gene_graph/Graph_data1"
#graph_file: ['train_graph_8.xlsx']
#graph_file: ['1-48node_train_graph_8.xlsx']
graph_file: ['48_node_train_graph_6.xlsx']


#seqloss_figure
DoYouNeedEpochSeqlossFigure: False

# training config
input_len: 504 # optimal
output_len: 168
capacity: 6
out_capacity: 1
patient: 10
var_len: 1 # diff should +1
#normalization method
MinMaxNormalization: True

#SegRNN
seg_len: 84

# model general param
gcn_k: 2   # for GCN
dilation_0: 4

dropout: 0.1  # dropout rate

#Informer param
out_dim: 4

# TCN-GCN model param
ks: 3   # kernel size of CausalConv2d
channels_list: [16, 32]   # featurefreq如何设置分钟 dimension 1->16->32...
d0: 1   # initial dilated rate
tcn_layers: [32,64]

conv_channels: 128



# GRU_GCN / GCN_LSTM / AGCRN model param
hidden_dim: 16   #hidden layer dimension of GRU
embed_dim: 10

# FCSTGNN
conv_out: 3
num_windows: 8
lstmout_dim: 32
hid_dim: 8
lstmhidden_dim: 8
conv_kernel: 2
moving_window: [5, 5]
stride: [1, 2]
pool_choice: 'mean'
decay: 0.7

# data setting
binary: True
weight_adj_epsilon: 0.4
dtw_topk: 2
train_normal_flag: True
test_normal_flag: True

#model
seed: 3407
num_workers: 0 #
epoch: 200
batch_size: 32 # optimal 16
output_path: "./output/"
log_per_steps: 1000
lr: 0.0001   # optimal
clip_norm: 5 #?
weight_decay: 0 #? trick
learner: "adam" # 1
lr_decay: False #? trick
lr_scheduler_type: None #?
lr_eta_min: 0.00001 #?
lr_decay_ratio: 0.1 #?
lr_warmup_epoch: 5 #?
lr_warmup_init: 0.000001 #?
loss: "FilterMSELoss" #
save_data_recon_er: False
